{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dadf5602-3c1d-4af8-8d90-8f26277d12f2",
   "metadata": {},
   "source": [
    "Q1. What is Bayes' theorem?\n",
    "\n",
    "Bayes' Theorem: It is a mathematical formula used to update the probabilities of hypotheses based on new evidence. It provides a way to revise existing predictions or theories given new or additional data.\n",
    "Q2. What is the formula for Bayes' theorem?\n",
    "\n",
    "Formula:\n",
    "P(A∣B)=P(B∣A)⋅P(A)P(B)P(A∣B)=P(B)P(B∣A)⋅P(A)​\n",
    "Where:\n",
    "\n",
    "    P(A∣B)P(A∣B) is the posterior probability of event A given event B.\n",
    "    P(B∣A)P(B∣A) is the likelihood of event B given event A.\n",
    "    P(A)P(A) is the prior probability of event A.\n",
    "    P(B)P(B) is the marginal probability of event B.\n",
    "\n",
    "Q3. How is Bayes' theorem used in practice?\n",
    "\n",
    "In Practice: Bayes' theorem is used in various fields such as machine learning (e.g., Naive Bayes classifiers), medicine (diagnosing diseases), finance (risk assessment), and spam filtering by updating the probability of a hypothesis as more evidence or information becomes available.\n",
    "Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
    "\n",
    "Relationship: Bayes' theorem is a way to express the relationship between two conditional probabilities. It shows how to compute the probability of a hypothesis given observed data (posterior probability) based on the likelihood of the observed data given the hypothesis and the prior probability of the hypothesis.\n",
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
    "\n",
    "Choosing a Naive Bayes Classifier:\n",
    "\n",
    "    Gaussian Naive Bayes: Use for continuous data that follow a Gaussian distribution.\n",
    "    Multinomial Naive Bayes: Use for discrete data with multiple counts, such as text classification.\n",
    "    Bernoulli Naive Bayes: Use for binary/Boolean features, where features are binary variables.\n",
    "\n",
    "Q6. Naive Bayes Classification Example\n",
    "\n",
    "Given Data:\n",
    "\n",
    "    Class A: X1={1:3, 2:3, 3:4}, X2={1:4, 2:3, 3:3, 4:3}\n",
    "    Class B: X1={1:2, 2:2, 3:1}, X2={1:2, 2:2, 3:2, 4:3}\n",
    "    New instance: X1=3, X2=4\n",
    "\n",
    "Calculations:\n",
    "\n",
    "    Prior Probabilities (assuming equal):\n",
    "        P(A)=0.5P(A)=0.5\n",
    "        P(B)=0.5P(B)=0.5\n",
    "\n",
    "    Likelihoods:\n",
    "        P(X1=3∣A)=4/10=0.4\n",
    "        P(X2=4∣A)=3/13≈0.23\n",
    "        P(X1=3∣B)=1/5=0.2\n",
    "        P(X2=4∣B)=3/9=0.33\n",
    "\n",
    "    Posteriors:\n",
    "        P(A∣X1=3,X2=4)∝P(X1=3∣A)⋅P(X2=4∣A)⋅P(A)≈0.4⋅0.23⋅0.5=0.046\n",
    "        P(B∣X1=3,X2=4)∝P(X1=3∣B)⋅P(X2=4∣B)⋅P(B)≈0.2⋅0.33⋅0.5=0.033P(B∣X1=3,X2=4)∝P(X1=3∣B)⋅P(X2=4∣B)⋅P(B)≈0.2⋅0.33⋅0.5=0.033\n",
    "\n",
    "Prediction: Since P(A∣X1=3,X2=4)>P(B∣X1=3,X2=4)P(A∣X1=3,X2=4)>P(B∣X1=3,X2=4), Naive Bayes would predict the new instance to belong to Class A.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
